{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled8.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM51yXoH/Qr6/bwMohwtigE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4d10312afa314432b34e6931a5b8b95d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_461f09f8797c461ba448ad6a373eedba",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_42843efcee0440099f4fd495944f31d1",
              "IPY_MODEL_48d2620fb87e4ac08cea27421bb6308d"
            ]
          }
        },
        "461f09f8797c461ba448ad6a373eedba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "42843efcee0440099f4fd495944f31d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_278b89e1dd584b719ccc2aa9727ecf28",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 669491321,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 669491321,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_482e80f0d1de4fd193a99d3300886011"
          }
        },
        "48d2620fb87e4ac08cea27421bb6308d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_73288393ce85491da222790683a87509",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 669M/669M [00:15&lt;00:00, 42.3MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5815a1ebb7b94a60a88f7ca2439d16b0"
          }
        },
        "278b89e1dd584b719ccc2aa9727ecf28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "482e80f0d1de4fd193a99d3300886011": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "73288393ce85491da222790683a87509": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5815a1ebb7b94a60a88f7ca2439d16b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KingYuanSun/Individual-Projects-NLP/blob/master/Sentiment_Analysis_StockTrendPrediction_Main_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zIXSKk5Y_DI",
        "colab_type": "text"
      },
      "source": [
        "BERT with Sentiment analysis¶\n",
        "In this notebook I used a pretrained version of BERT avaliable as a huggingface transformed to classify the sentiment of news articles about Bitcoin and Tesla, and applied an LSTM to predict the stock returns\n",
        "\n",
        "Sources\n",
        "https://towardsdatascience.com/fine-tuning-bert-with-keras-and-tf-module-ed24ea91cff2\n",
        "\n",
        "Bert for dummies: https://towardsdatascience.com/bert-for-dummies-step-by-step-tutorial-fb90890ffe03\n",
        "Bert for long texts: https://medium.com/@armandj.olivares/using-bert-for-classifying-documents-with-long-texts-5c3e7b04573d\n",
        "googles notebook: https://github.com/google-research/bert/blob/master/predicting_movie_reviews_with_bert_on_tf_hub.ipynb\n",
        "strong.io: https://towardsdatascience.com/bert-in-keras-with-tensorflow-hub-76bcbc9417b\n",
        "strong.io notebook : https://github.com/strongio/keras-bert\n",
        "https://keras.io/layers/writing-your-own-keras-layers/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOWNlneVaHc8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "096a3bbc-b8ab-4738-b92a-52ba9ccbff7b"
      },
      "source": [
        "!pip install utils\n",
        "!pip install bert-for-tf2\n",
        "!pip install numpy\n",
        "!pip install pandas\n",
        "!pip install matplotlib\n",
        "!pip install nltk\n",
        "!pip install yfinance\n",
        "!pip install news-please\n",
        "!pip install google\n",
        "!pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting utils\n",
            "  Downloading https://files.pythonhosted.org/packages/55/e6/c2d2b2703e7debc8b501caae0e6f7ead148fd0faa3c8131292a599930029/utils-1.0.1-py2.py3-none-any.whl\n",
            "Installing collected packages: utils\n",
            "Successfully installed utils-1.0.1\n",
            "Collecting bert-for-tf2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/df/ab6d927d6162657f30eb0ae3c534c723c28c191a9caf6ee68ec935df3d0b/bert-for-tf2-0.14.5.tar.gz (40kB)\n",
            "\u001b[K     |████████████████████████████████| 40kB 1.2MB/s \n",
            "\u001b[?25hCollecting py-params>=0.9.6\n",
            "  Downloading https://files.pythonhosted.org/packages/a4/bf/c1c70d5315a8677310ea10a41cfc41c5970d9b37c31f9c90d4ab98021fd1/py-params-0.9.7.tar.gz\n",
            "Collecting params-flow>=0.8.0\n",
            "  Downloading https://files.pythonhosted.org/packages/a9/95/ff49f5ebd501f142a6f0aaf42bcfd1c192dc54909d1d9eb84ab031d46056/params-flow-0.8.2.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (1.18.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (4.41.1)\n",
            "Building wheels for collected packages: bert-for-tf2, py-params, params-flow\n",
            "  Building wheel for bert-for-tf2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bert-for-tf2: filename=bert_for_tf2-0.14.5-cp36-none-any.whl size=30315 sha256=5b29b19cc8ad7720839a8e419ae6094d341e47a321a8f13f00c2cfaa6968a8f9\n",
            "  Stored in directory: /root/.cache/pip/wheels/2e/70/a2/be357037dd2cbdcaeb0add1fdf083be6a600ca65ee1f68751c\n",
            "  Building wheel for py-params (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-params: filename=py_params-0.9.7-cp36-none-any.whl size=7302 sha256=4861ad2be7460abccceeafb49dbe8c0b770f5d8819b0b055c889182dab3e5243\n",
            "  Stored in directory: /root/.cache/pip/wheels/67/f5/19/b461849a50aefdf4bab47c4756596e82ee2118b8278e5a1980\n",
            "  Building wheel for params-flow (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for params-flow: filename=params_flow-0.8.2-cp36-none-any.whl size=19473 sha256=19c743c863d6565b74d726caa97edb99004a2a4d7aad09fa66a312bb60579321\n",
            "  Stored in directory: /root/.cache/pip/wheels/08/c8/7f/81c86b9ff2b86e2c477e3914175be03e679e596067dc630c06\n",
            "Successfully built bert-for-tf2 py-params params-flow\n",
            "Installing collected packages: py-params, params-flow, bert-for-tf2\n",
            "Successfully installed bert-for-tf2-0.14.5 params-flow-0.8.2 py-params-0.9.7\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.18.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (1.0.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.18.5)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas) (1.15.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (3.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.4.7)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.18.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.15.0)\n",
            "Collecting yfinance\n",
            "  Downloading https://files.pythonhosted.org/packages/c2/31/8b374a12b90def92a4e27d0fc595fc43635f395984e36a075244d98bd265/yfinance-0.1.54.tar.gz\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.6/dist-packages (from yfinance) (1.0.5)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.6/dist-packages (from yfinance) (1.18.5)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.6/dist-packages (from yfinance) (2.23.0)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from yfinance) (0.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24->yfinance) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24->yfinance) (2018.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20->yfinance) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20->yfinance) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20->yfinance) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20->yfinance) (3.0.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas>=0.24->yfinance) (1.15.0)\n",
            "Building wheels for collected packages: yfinance\n",
            "  Building wheel for yfinance (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for yfinance: filename=yfinance-0.1.54-py2.py3-none-any.whl size=22409 sha256=661dccab81362710c2e5b477972b77577743da3e47a70eddf93b46c12bf00232\n",
            "  Stored in directory: /root/.cache/pip/wheels/f9/e3/5b/ec24dd2984b12d61e0abf26289746c2436a0e7844f26f2515c\n",
            "Successfully built yfinance\n",
            "Installing collected packages: yfinance\n",
            "Successfully installed yfinance-0.1.54\n",
            "Collecting news-please\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/d8/0331d1e1da5eaffa4b8eafff120a006ecbfc9fef0f46e0f3f2b04e5a3770/news-please-1.5.3.tar.gz (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 2.1MB/s \n",
            "\u001b[?25hCollecting Scrapy>=1.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/58/59/a942878de3fb03481207a32bea488d7c3bd6bd8deecdbf90b6746dfa2da0/Scrapy-2.3.0-py2.py3-none-any.whl (237kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 7.1MB/s \n",
            "\u001b[?25hCollecting PyMySQL>=0.7.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2c/57/af502e0e113f139b3f3add4f1efba899a730a365d2264d476e85b9591da5/PyMySQL-0.10.0-py2.py3-none-any.whl (47kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.4MB/s \n",
            "\u001b[?25hCollecting psycopg2-binary>=2.8.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d3/8a/a7ed55c2c55bd4f5844d72734fedc0cef8a74518a0a19105a21c15628f1e/psycopg2_binary-2.8.5-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 14.4MB/s \n",
            "\u001b[?25hCollecting hjson>=1.5.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8a/92/6b6b85064f8a88cb3b31901d839e7b45c33e4ee450bb1b3cf0c226cca8ec/hjson-3.0.1.tar.gz (43kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.6MB/s \n",
            "\u001b[?25hCollecting elasticsearch>=2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/7f/8dd4c7e1895d99e16c9b78fea1e0e0a64382f53bc9fc655a01465de70505/elasticsearch-7.8.1-py2.py3-none-any.whl (188kB)\n",
            "\u001b[K     |████████████████████████████████| 194kB 30.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: beautifulsoup4>=4.3.2 in /usr/local/lib/python3.6/dist-packages (from news-please) (4.6.3)\n",
            "Collecting readability-lxml>=0.6.2\n",
            "  Downloading https://files.pythonhosted.org/packages/39/a6/cfe22aaa19ac69b97d127043a76a5bbcb0ef24f3a0b22793c46608190caa/readability_lxml-0.8.1-py3-none-any.whl\n",
            "Collecting newspaper3k>=0.2.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/b9/51afecb35bb61b188a4b44868001de348a0e8134b4dfa00ffc191567c4b9/newspaper3k-0.2.8-py3-none-any.whl (211kB)\n",
            "\u001b[K     |████████████████████████████████| 215kB 30.6MB/s \n",
            "\u001b[?25hCollecting langdetect>=1.0.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/a3/8407c1e62d5980188b4acc45ef3d94b933d14a2ebc9ef3505f22cf772570/langdetect-1.0.8.tar.gz (981kB)\n",
            "\u001b[K     |████████████████████████████████| 983kB 23.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.4.0 in /usr/local/lib/python3.6/dist-packages (from news-please) (2.8.1)\n",
            "Requirement already satisfied: plac>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from news-please) (1.1.3)\n",
            "Collecting dotmap>=1.2.17\n",
            "  Downloading https://files.pythonhosted.org/packages/52/47/9ca39d01b872c1bf2da0f0031cb3c4e3a016170c181e34d889253e404d59/dotmap-1.3.17-py3-none-any.whl\n",
            "Collecting PyDispatcher>=2.0.5\n",
            "  Downloading https://files.pythonhosted.org/packages/cd/37/39aca520918ce1935bea9c356bcbb7ed7e52ad4e31bff9b943dfc8e7115b/PyDispatcher-2.0.5.tar.gz\n",
            "Collecting warcio>=1.3.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/24/eb/060b7e1c76abf24692784d5cf9c52ec05ff21249c88515d7f03c676434db/warcio-1.7.4-py2.py3-none-any.whl (40kB)\n",
            "\u001b[K     |████████████████████████████████| 40kB 2.7MB/s \n",
            "\u001b[?25hCollecting ago>=0.0.9\n",
            "  Downloading https://files.pythonhosted.org/packages/f8/4e/976bd88566b0feec295873c3aa5a8712219edb2c07c7f6723c831e8840bd/ago-0.0.93.tar.gz\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from news-please) (1.15.0)\n",
            "Requirement already satisfied: lxml>=3.3.5 in /usr/local/lib/python3.6/dist-packages (from news-please) (4.2.6)\n",
            "Collecting awscli>=1.11.117\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e8/0c/34e5c55210584984a51077a0a0e1fcb6efff31f605a7e8c4d70babb1761d/awscli-1.18.120-py2.py3-none-any.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 44.9MB/s \n",
            "\u001b[?25hCollecting hurry.filesize>=0.9\n",
            "  Downloading https://files.pythonhosted.org/packages/ee/5e/16e17bedcf54d5b618dc0771690deda77178e5c310402881c3d2d6c5f27c/hurry.filesize-0.9.tar.gz\n",
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.6/dist-packages (from news-please) (0.0.1)\n",
            "Collecting cssselect>=0.9.1\n",
            "  Downloading https://files.pythonhosted.org/packages/3b/d4/3b5c17f00cce85b9a1e6f91096e1cc8e8ede2e1be8e96b87ce1ed09e92c5/cssselect-1.1.0-py2.py3-none-any.whl\n",
            "Collecting pyOpenSSL>=16.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/de/f8342b68fa9e981d348039954657bdf681b2ab93de27443be51865ffa310/pyOpenSSL-19.1.0-py2.py3-none-any.whl (53kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 6.2MB/s \n",
            "\u001b[?25hCollecting itemadapter>=0.1.0\n",
            "  Downloading https://files.pythonhosted.org/packages/7d/fb/92f848fcfa85dc9f95370eaecb5c99b5230dd4fc5c6bae684f4ca59df973/itemadapter-0.1.0-py3-none-any.whl\n",
            "Collecting zope.interface>=4.1.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/57/33/565274c28a11af60b7cfc0519d46bde4125fcd7d32ebc0a81b480d0e8da6/zope.interface-5.1.0-cp36-cp36m-manylinux2010_x86_64.whl (234kB)\n",
            "\u001b[K     |████████████████████████████████| 235kB 42.4MB/s \n",
            "\u001b[?25hCollecting parsel>=1.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/23/1e/9b39d64cbab79d4362cdd7be7f5e9623d45c4a53b3f7522cd8210df52d8e/parsel-1.6.0-py2.py3-none-any.whl\n",
            "Collecting Twisted>=17.9.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b7/04/1a664c9e5ec0224a1c1a154ddecaa4dc7b8967521bba225efcc41a03d5f3/Twisted-20.3.0-cp36-cp36m-manylinux1_x86_64.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1MB 44.7MB/s \n",
            "\u001b[?25hCollecting w3lib>=1.17.0\n",
            "  Downloading https://files.pythonhosted.org/packages/a3/59/b6b14521090e7f42669cafdb84b0ab89301a42f1f1a82fcf5856661ea3a7/w3lib-1.22.0-py2.py3-none-any.whl\n",
            "Collecting cryptography>=2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ba/91/84a29d6a27fd6dfc21f475704c4d2053d58ed7a4033c2b0ce1b4ca4d03d9/cryptography-3.0-cp35-abi3-manylinux2010_x86_64.whl (2.7MB)\n",
            "\u001b[K     |████████████████████████████████| 2.7MB 47.8MB/s \n",
            "\u001b[?25hCollecting itemloaders>=1.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/a8/53/3855a2f5496d8effe895ba87eced19984501dd00f289b5048040b87bb542/itemloaders-1.0.2-py3-none-any.whl\n",
            "Collecting protego>=0.1.15\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/db/6e/bf6d5e4d7cf233b785719aaec2c38f027b9c2ed980a0015ec1a1cced4893/Protego-0.1.16.tar.gz (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 48.8MB/s \n",
            "\u001b[?25hCollecting service-identity>=16.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/e9/7c/2195b890023e098f9618d43ebc337d83c8b38d414326685339eb024db2f6/service_identity-18.1.0-py2.py3-none-any.whl\n",
            "Collecting queuelib>=1.4.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4c/85/ae64e9145f39dd6d14f8af3fa809a270ef3729f3b90b3c0cf5aa242ab0d4/queuelib-1.5.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from elasticsearch>=2.4->news-please) (2020.6.20)\n",
            "Requirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from elasticsearch>=2.4->news-please) (1.24.3)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.6/dist-packages (from readability-lxml>=0.6.2->news-please) (3.0.4)\n",
            "Requirement already satisfied: nltk>=3.2.1 in /usr/local/lib/python3.6/dist-packages (from newspaper3k>=0.2.8->news-please) (3.2.5)\n",
            "Requirement already satisfied: PyYAML>=3.11 in /usr/local/lib/python3.6/dist-packages (from newspaper3k>=0.2.8->news-please) (3.13)\n",
            "Collecting tldextract>=2.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/12/cf/d0ff82625e53bd245d6173ce6333d190abbfcd94e4c30e54b4e16b474216/tldextract-2.2.3-py2.py3-none-any.whl (48kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 4.2MB/s \n",
            "\u001b[?25hCollecting feedfinder2>=0.0.4\n",
            "  Downloading https://files.pythonhosted.org/packages/35/82/1251fefec3bb4b03fd966c7e7f7a41c9fc2bb00d823a34c13f847fd61406/feedfinder2-0.0.4.tar.gz\n",
            "Collecting tinysegmenter==0.3\n",
            "  Downloading https://files.pythonhosted.org/packages/17/82/86982e4b6d16e4febc79c2a1d68ee3b707e8a020c5d2bc4af8052d0f136a/tinysegmenter-0.3.tar.gz\n",
            "Requirement already satisfied: Pillow>=3.3.0 in /usr/local/lib/python3.6/dist-packages (from newspaper3k>=0.2.8->news-please) (7.0.0)\n",
            "Collecting jieba3k>=0.35.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a9/cb/2c8332bcdc14d33b0bedd18ae0a4981a069c3513e445120da3c3f23a8aaa/jieba3k-0.35.1.zip (7.4MB)\n",
            "\u001b[K     |████████████████████████████████| 7.4MB 44.2MB/s \n",
            "\u001b[?25hCollecting feedparser>=5.2.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/d8/7d37fec71ff7c9dbcdd80d2b48bcdd86d6af502156fc93846fb0102cb2c4/feedparser-5.2.1.tar.bz2 (192kB)\n",
            "\u001b[K     |████████████████████████████████| 194kB 45.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from newspaper3k>=0.2.8->news-please) (2.23.0)\n",
            "Collecting botocore==1.17.43\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/c1/e6675d8fd48c86612c0a8bf15e6c6b0aad43feb6308fb7f62102119d1304/botocore-1.17.43-py2.py3-none-any.whl (6.5MB)\n",
            "\u001b[K     |████████████████████████████████| 6.5MB 43.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from awscli>=1.11.117->news-please) (0.15.2)\n",
            "Collecting colorama<0.4.4,>=0.2.5; python_version != \"3.4\"\n",
            "  Downloading https://files.pythonhosted.org/packages/c9/dc/45cdef1b4d119eb96316b3117e6d5708a08029992b2fee2c143c7a0a5cc5/colorama-0.4.3-py2.py3-none-any.whl\n",
            "Collecting rsa<=4.5.0,>=3.1.2; python_version != \"3.4\"\n",
            "  Downloading https://files.pythonhosted.org/packages/26/f8/8127fdda0294f044121d20aac7785feb810e159098447967a6103dedfb96/rsa-4.5-py2.py3-none-any.whl\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from awscli>=1.11.117->news-please) (0.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from hurry.filesize>=0.9->news-please) (49.2.0)\n",
            "Collecting hyperlink>=17.1.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/88/a5/74f77547e9b175eb894d4fec5c76b0c8176c045e5bf3ac6a4d4d3feab4bb/hyperlink-20.0.1-py2.py3-none-any.whl (48kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.7MB/s \n",
            "\u001b[?25hCollecting incremental>=16.10.1\n",
            "  Downloading https://files.pythonhosted.org/packages/f5/1d/c98a587dc06e107115cf4a58b49de20b19222c83d75335a192052af4c4b7/incremental-17.5.0-py2.py3-none-any.whl\n",
            "Collecting PyHamcrest!=1.10.0,>=1.9.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/16/e54cc65891f01cb62893540f44ffd3e8dab0a22443e1b438f1a9f5574bee/PyHamcrest-2.0.2-py3-none-any.whl (52kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 7.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.6/dist-packages (from Twisted>=17.9.0->Scrapy>=1.1.0->news-please) (19.3.0)\n",
            "Collecting constantly>=15.1\n",
            "  Downloading https://files.pythonhosted.org/packages/b9/65/48c1909d0c0aeae6c10213340ce682db01b48ea900a7d9fce7a7910ff318/constantly-15.1.0-py2.py3-none-any.whl\n",
            "Collecting Automat>=0.3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/dd/83/5f6f3c1a562674d65efc320257bdc0873ec53147835aeef7762fe7585273/Automat-20.2.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: cffi!=1.11.3,>=1.8 in /usr/local/lib/python3.6/dist-packages (from cryptography>=2.0->Scrapy>=1.1.0->news-please) (1.14.1)\n",
            "Requirement already satisfied: jmespath>=0.9.5 in /usr/local/lib/python3.6/dist-packages (from itemloaders>=1.0.1->Scrapy>=1.1.0->news-please) (0.10.0)\n",
            "Requirement already satisfied: pyasn1 in /usr/local/lib/python3.6/dist-packages (from service-identity>=16.0.0->Scrapy>=1.1.0->news-please) (0.4.8)\n",
            "Requirement already satisfied: pyasn1-modules in /usr/local/lib/python3.6/dist-packages (from service-identity>=16.0.0->Scrapy>=1.1.0->news-please) (0.2.8)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.6/dist-packages (from tldextract>=2.0.1->newspaper3k>=0.2.8->news-please) (2.10)\n",
            "Collecting requests-file>=1.4\n",
            "  Downloading https://files.pythonhosted.org/packages/77/86/cdb5e8eaed90796aa83a6d9f75cfbd37af553c47a291cd47bc410ef9bdb2/requests_file-1.5.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi!=1.11.3,>=1.8->cryptography>=2.0->Scrapy>=1.1.0->news-please) (2.20)\n",
            "Building wheels for collected packages: news-please, hjson, langdetect, PyDispatcher, ago, hurry.filesize, protego, feedfinder2, tinysegmenter, jieba3k, feedparser\n",
            "  Building wheel for news-please (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for news-please: filename=news_please-1.5.3-cp36-none-any.whl size=85319 sha256=202d5767ccbbb4d868b0b90de0586a8a922fb518875b0be2b85471bd41956e89\n",
            "  Stored in directory: /root/.cache/pip/wheels/8a/1f/6a/cccc90f55811ec4ae122265c6722c15af27dbcb95e7a40db1c\n",
            "  Building wheel for hjson (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hjson: filename=hjson-3.0.1-cp36-none-any.whl size=54145 sha256=67ebfcb4ad3af68e9c3f53383fa3900be9004cb1e1a0d26672af2014fd5b19aa\n",
            "  Stored in directory: /root/.cache/pip/wheels/34/2a/5b/254bcb7475d861a2bdc1f8f32f9924734b4e045a7c8dd596ae\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.8-cp36-none-any.whl size=993193 sha256=c68a7ba1dab79f7797631dda1632a55ada9066c37df8fedbd2607f9f778d5e58\n",
            "  Stored in directory: /root/.cache/pip/wheels/8d/b3/aa/6d99de9f3841d7d3d40a60ea06e6d669e8e5012e6c8b947a57\n",
            "  Building wheel for PyDispatcher (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyDispatcher: filename=PyDispatcher-2.0.5-cp36-none-any.whl size=11515 sha256=e9a55699852425af6b12a0897af4ef464f6871656590c26ff33df9c5cf4a79ae\n",
            "  Stored in directory: /root/.cache/pip/wheels/88/99/96/cfef6665f9cb1522ee6757ae5955feedf2fe25f1737f91fa7f\n",
            "  Building wheel for ago (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ago: filename=ago-0.0.93-cp36-none-any.whl size=3275 sha256=02793cb36b3bebdb1a47fbebe7290089340ca8da213392dc3c56fe1a7c50a6f8\n",
            "  Stored in directory: /root/.cache/pip/wheels/86/65/dc/27df15b96de756d2e07bc01433067df2e6ace2bae8de0576a2\n",
            "  Building wheel for hurry.filesize (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hurry.filesize: filename=hurry.filesize-0.9-cp36-none-any.whl size=4134 sha256=f545034e3947c78d225be7773f3025ca1c024e083a4029c61bae3ab8e6a109f5\n",
            "  Stored in directory: /root/.cache/pip/wheels/2c/2b/7d/b63fffa26fe9949c4c44f226c566387b72617269c94b89eded\n",
            "  Building wheel for protego (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for protego: filename=Protego-0.1.16-cp36-none-any.whl size=7765 sha256=0c18fa3cd6c08178ddc0f7ab95e11db31f810560c8fda7d16eef6a7c56341899\n",
            "  Stored in directory: /root/.cache/pip/wheels/51/01/d1/4a2286a976dccd025ba679acacfe37320540df0f2283ecab12\n",
            "  Building wheel for feedfinder2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for feedfinder2: filename=feedfinder2-0.0.4-cp36-none-any.whl size=3357 sha256=dbbff1c8a58e19ced477117c41bf3fa5d296aecec158210c946d7901c782338e\n",
            "  Stored in directory: /root/.cache/pip/wheels/de/03/ca/778e3a7a627e3d98836cc890e7cb40c7575424cfd3340f40ed\n",
            "  Building wheel for tinysegmenter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tinysegmenter: filename=tinysegmenter-0.3-cp36-none-any.whl size=13539 sha256=a06bb7805d5f97ec4ba42346448de930f07f32672d9f8f18d103196ac088553f\n",
            "  Stored in directory: /root/.cache/pip/wheels/81/2b/43/a02ede72324dd40cdd7ca53aad718c7710628e91b8b0dc0f02\n",
            "  Building wheel for jieba3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jieba3k: filename=jieba3k-0.35.1-cp36-none-any.whl size=7398406 sha256=3fcd7590dba5aca74cb2bc82bf3ac616f88a5e98828d32f64d1f40e4221cd2fa\n",
            "  Stored in directory: /root/.cache/pip/wheels/83/15/9c/a3f1f67e7f7181170ad37d32e503c35da20627c013f438ed34\n",
            "  Building wheel for feedparser (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for feedparser: filename=feedparser-5.2.1-cp36-none-any.whl size=44940 sha256=5614d08a75a70b117bd665d1c277ffbd9c754f7ef5ba9c14f615b184ee7ab25f\n",
            "  Stored in directory: /root/.cache/pip/wheels/8c/69/b7/f52763c41c5471df57703a0ef718a32a5e81ee35dcf6d4f97f\n",
            "Successfully built news-please hjson langdetect PyDispatcher ago hurry.filesize protego feedfinder2 tinysegmenter jieba3k feedparser\n",
            "Installing collected packages: cssselect, cryptography, pyOpenSSL, itemadapter, zope.interface, w3lib, parsel, PyDispatcher, hyperlink, incremental, PyHamcrest, constantly, Automat, Twisted, itemloaders, protego, service-identity, queuelib, Scrapy, PyMySQL, psycopg2-binary, hjson, elasticsearch, readability-lxml, requests-file, tldextract, feedfinder2, tinysegmenter, jieba3k, feedparser, newspaper3k, langdetect, dotmap, warcio, ago, botocore, colorama, rsa, awscli, hurry.filesize, news-please\n",
            "  Found existing installation: botocore 1.17.37\n",
            "    Uninstalling botocore-1.17.37:\n",
            "      Successfully uninstalled botocore-1.17.37\n",
            "  Found existing installation: rsa 4.6\n",
            "    Uninstalling rsa-4.6:\n",
            "      Successfully uninstalled rsa-4.6\n",
            "Successfully installed Automat-20.2.0 PyDispatcher-2.0.5 PyHamcrest-2.0.2 PyMySQL-0.10.0 Scrapy-2.3.0 Twisted-20.3.0 ago-0.0.93 awscli-1.18.120 botocore-1.17.43 colorama-0.4.3 constantly-15.1.0 cryptography-3.0 cssselect-1.1.0 dotmap-1.3.17 elasticsearch-7.8.1 feedfinder2-0.0.4 feedparser-5.2.1 hjson-3.0.1 hurry.filesize-0.9 hyperlink-20.0.1 incremental-17.5.0 itemadapter-0.1.0 itemloaders-1.0.2 jieba3k-0.35.1 langdetect-1.0.8 news-please-1.5.3 newspaper3k-0.2.8 parsel-1.6.0 protego-0.1.16 psycopg2-binary-2.8.5 pyOpenSSL-19.1.0 queuelib-1.5.0 readability-lxml-0.8.1 requests-file-1.5.1 rsa-4.5 service-identity-18.1.0 tinysegmenter-0.3 tldextract-2.2.3 w3lib-1.22.0 warcio-1.7.4 zope.interface-5.1.0\n",
            "Requirement already satisfied: google in /usr/local/lib/python3.6/dist-packages (2.0.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from google) (4.6.3)\n",
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n",
            "\u001b[K     |████████████████████████████████| 778kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 14.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Collecting tokenizers==0.8.1.rc1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/d0/30d5f8d221a0ed981a186c8eb986ce1c94e3a6e87f994eae9f4aa5250217/tokenizers-0.8.1rc1-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 17.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 44.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=752068e55a3f44ffb6b4bdc58aca7f89c8fc99c47996310352393fc9b4d4b0c3\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc1 transformers-3.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4oWOzCQAdm7s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##utils.py\n",
        "\n",
        "import pandas as pd, numpy as np\n",
        "try:\n",
        "\timport bert\n",
        "except:\n",
        "\tprint(\"bert-for-tf2 not installed\")\n",
        "\n",
        "# transforms sentences to ids, masks and segment ids prepared to feed bert\n",
        "def convert_sentence_to_features(sentence, tokenizer, max_seq_len):\n",
        "    tokens = ['[CLS]']\n",
        "    tokens.extend(tokenizer.tokenize(sentence))\n",
        "    if len(tokens) > max_seq_len-1:\n",
        "        tokens = tokens[:max_seq_len-1]\n",
        "    tokens.append('[SEP]')\n",
        "    \n",
        "    segment_ids = [0] * len(tokens)\n",
        "    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "    input_mask = [1] * len(input_ids)\n",
        "\n",
        "    #Zero Mask till seq_length\n",
        "    zero_mask = [0] * (max_seq_len-len(tokens))\n",
        "    input_ids.extend(zero_mask)\n",
        "    input_mask.extend(zero_mask)\n",
        "    segment_ids.extend(zero_mask)\n",
        "    \n",
        "    return input_ids, input_mask, segment_ids\n",
        "\n",
        "def convert_sentences_to_features(sentences, tokenizer, max_seq_len=200):\n",
        "    all_input_ids = []\n",
        "    all_input_mask = []\n",
        "    all_segment_ids = []\n",
        "    \n",
        "    for sentence in sentences:\n",
        "        input_ids, input_mask, segment_ids = convert_sentence_to_features(sentence, tokenizer, max_seq_len)\n",
        "        all_input_ids.append(input_ids)\n",
        "        all_input_mask.append(input_mask)\n",
        "        all_segment_ids.append(segment_ids)\n",
        "    \n",
        "    return all_input_ids, all_input_mask, all_segment_ids\n",
        "\n",
        "def generate_data_for_tokenizer(split_text,target_series):\n",
        "    labels_list = []\n",
        "    dates = []\n",
        "    for date, arrays in split_text.itertuples():\n",
        "        dates.extend([date]* len(arrays))\n",
        "    for date in dates:\n",
        "        labels_list.append(target_series.loc[date])\n",
        "    \n",
        "    split_text_flat = split_text.values.flatten()\n",
        "    sentence_list = [sentence for array in split_text_flat for sentence in array]\n",
        "    \n",
        "    labels = pd.DataFrame(labels_list, index = dates)\n",
        "    sentences  = pd.DataFrame(sentence_list, index = dates)\n",
        "    return sentences, labels\n",
        "\n",
        "# given an input text and a set of keywords, returns the top_n_terms which contain any of the keywords by frequency of appearance.\n",
        "def find_new_token_with_custom_keywords(array_of_text, custom_keywords, top_n_terms, extra_tokens):\n",
        "    \n",
        "    def contains_keyword(word,keywords):\n",
        "        for k in keywords:\n",
        "            if word.find(k) >= 0:\n",
        "                return True\n",
        "        return False\n",
        "    \n",
        "    def count_frequency(my_list): \n",
        "        freq = {} \n",
        "        for item in my_list: \n",
        "            if (item in freq): \n",
        "                freq[item] += 1\n",
        "            else: \n",
        "                freq[item] = 1\n",
        "        return freq\n",
        "    \n",
        "    raw_text = \"\".join(array_of_text).replace(\".com\",\"-com\").replace(\".\", \"\").replace(\",\", \"\").replace(\"\\n\", \" \").replace(\"-com\",\".com\")\n",
        "    raw_words = raw_text.split(\" \")\n",
        "    matches = []\n",
        "    for word in raw_words:\n",
        "        if contains_keyword(word.lower(),custom_keywords):\n",
        "            matches.append(word.lower())\n",
        "    \n",
        "    matches_count = count_frequency(matches)\n",
        "    #sorts the counts\n",
        "    #matches_dict = {k: v for k, v in sorted(matches_count.items(), key=lambda item: item[1], reverse = True)}\n",
        "    # selects top n words from the list\n",
        "    #new_tokens = list(matches_dict)[:top_n_terms]  + extra_tokens\n",
        "    import operator\n",
        "    sorted_x = sorted(matches_count.items(), key=operator.itemgetter(1), reverse = True)\n",
        "    new_tokens = [ tup[0] for tup in sorted_x[:top_n_terms]]  + extra_tokens\n",
        "    \n",
        "    print(\"New tokens to be added: \",new_tokens)\n",
        "    return new_tokens\n",
        "\n",
        "# creates bert tokenizer\n",
        "def create_tokenizer(vocab_file='vocab.txt', do_lower_case=True):\n",
        "    return bert.bert_tokenization.FullTokenizer(vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
        "\n",
        "# appends extra tokens to the vocab of the tokenizer\n",
        "def add_new_tokens(new_vocab, tokenizer):\n",
        "    for i in range(len(new_vocab)):\n",
        "        new_key = new_vocab[i]\n",
        "        old_key = \"[unused{}]\".format(i)\n",
        "        value = tokenizer.vocab.pop(old_key)\n",
        "        tokenizer.vocab[new_key] = value\n",
        "    return tokenizer\n",
        "\n",
        "# transforms bet output in one continuous series removing the padding\n",
        "def bert_output_to_one_time_series_per_day(bert_inputs, bert_output, sentences):\n",
        "    n_sentences = sentences.groupby(sentences.index).count()\n",
        "    n_tokens = bert_inputs[\"input_mask\"][:].sum(axis = 1)\n",
        "    mask_out = [bert_output[1][counter,:length,:] for length, counter in zip(n_tokens,range(len(n_tokens)))]\n",
        "    \n",
        "    articles_per_day = []\n",
        "    acc = 0\n",
        "    for n in n_sentences.values:\n",
        "        n = n[0]\n",
        "        concat_articles = np.array(mask_out[acc:acc + n])\n",
        "        flattened = []\n",
        "        for sentence in concat_articles:\n",
        "            for token in sentence:\n",
        "                flattened.append(token)\n",
        "        flattened = np.array(flattened)\n",
        "        #flattened = np.array([token for token in sentence for sentence in concat_articles])\n",
        "        articles_per_day.append(flattened)\n",
        "        acc += n\n",
        "    return np.array(articles_per_day)\n",
        "\n",
        "# prepares_labels\n",
        "def label_transformer(prices, mode = \"returns\", shift = 5, index = None, standarized = False):\n",
        "    prices = pd.DataFrame(prices)\n",
        "    prices.columns = [\"today\"]\n",
        "    if index is not None:\n",
        "        prices = prices[index]\n",
        "    prices[\"tomorrow\"] = prices.shift(1)\n",
        "    prices[\"returns\"] = prices[\"today\"].pct_change()\n",
        "    prices[\"diff\"] = prices[\"today\"] - prices[\"tomorrow\"]\n",
        "    def standard(df):\n",
        "        return (df - df.mean())/df.std()\n",
        "    output = prices[mode].shift(shift).dropna()\n",
        "    return output if not standarized else standard(output)\n",
        "\n",
        "# computes and returns intersection among series\n",
        "def series_intersection(a,b):\n",
        "    a.index = pd.DatetimeIndex(a.index)\n",
        "    b.index = pd.DatetimeIndex(b.index)\n",
        "    intersection = pd.DatetimeIndex([value for value in a.index if value in b.index])\n",
        "    return a.loc[intersection], b.loc[intersection]\n",
        "\n",
        "\n",
        "\n",
        "def rolling_window_bert_2nd_dim(a, window):\n",
        "    shape = (a.shape[0] - window + 1, window, a.shape[1])\n",
        "    strides = (a.strides[0], a.strides[1]*a.shape[1], a.strides[1])\n",
        "    #print(shape, strides)\n",
        "    return np.lib.stride_tricks.as_strided(a, shape=shape, strides=strides)\n",
        "\n",
        "\n",
        "def dummy():\n",
        "\treturn \"dah\""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hx1uhty9fHtR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "\n",
        "\n",
        "class Classifier_INCEPTION:\n",
        "\n",
        "    def __init__(self, output_directory, input_shape, nb_classes, verbose=False, build=True, batch_size=64,\n",
        "                 nb_filters=32, use_residual=True, use_bottleneck=True, depth=6, kernel_size=41, nb_epochs=1500):\n",
        "\n",
        "        self.output_directory = output_directory\n",
        "\n",
        "        self.nb_filters = nb_filters\n",
        "        self.use_residual = use_residual\n",
        "        self.use_bottleneck = use_bottleneck\n",
        "        self.depth = depth\n",
        "        self.kernel_size = kernel_size - 1\n",
        "        self.callbacks = None\n",
        "        self.batch_size = batch_size\n",
        "        self.bottleneck_size = 32\n",
        "        self.nb_epochs = nb_epochs\n",
        "\n",
        "        if build == True:\n",
        "            self.model = self.build_model(input_shape, nb_classes)\n",
        "            if (verbose == True):\n",
        "                self.model.summary()\n",
        "            self.verbose = verbose\n",
        "            self.model.save_weights(self.output_directory + 'model_init.hdf5')\n",
        "\n",
        "    def _inception_module(self, input_tensor, stride=1, activation='linear'):\n",
        "\n",
        "        if self.use_bottleneck and int(input_tensor.shape[-1]) > 1:\n",
        "            input_inception = keras.layers.Conv1D(filters=self.bottleneck_size, kernel_size=1,\n",
        "                                                  padding='same', activation=activation, use_bias=False)(input_tensor)\n",
        "        else:\n",
        "            input_inception = input_tensor\n",
        "\n",
        "        # kernel_size_s = [3, 5, 8, 11, 17]\n",
        "        kernel_size_s = [self.kernel_size // (2 ** i) for i in range(3)]\n",
        "\n",
        "        conv_list = []\n",
        "\n",
        "        for i in range(len(kernel_size_s)):\n",
        "            conv_list.append(keras.layers.Conv1D(filters=self.nb_filters, kernel_size=kernel_size_s[i],\n",
        "                                                 strides=stride, padding='same', activation=activation, use_bias=False)(\n",
        "                input_inception))\n",
        "\n",
        "        max_pool_1 = keras.layers.MaxPool1D(pool_size=3, strides=stride, padding='same')(input_tensor)\n",
        "\n",
        "        conv_6 = keras.layers.Conv1D(filters=self.nb_filters, kernel_size=1,\n",
        "                                     padding='same', activation=activation, use_bias=False)(max_pool_1)\n",
        "\n",
        "        conv_list.append(conv_6)\n",
        "\n",
        "        x = keras.layers.Concatenate(axis=2)(conv_list)\n",
        "        x = keras.layers.BatchNormalization()(x)\n",
        "        x = keras.layers.Activation(activation='relu')(x)\n",
        "        return x\n",
        "\n",
        "    def _shortcut_layer(self, input_tensor, out_tensor):\n",
        "        shortcut_y = keras.layers.Conv1D(filters=int(out_tensor.shape[-1]), kernel_size=1,\n",
        "                                         padding='same', use_bias=False)(input_tensor)\n",
        "        shortcut_y = keras.layers.BatchNormalization()(shortcut_y)\n",
        "\n",
        "        x = keras.layers.Add()([shortcut_y, out_tensor])\n",
        "        x = keras.layers.Activation('relu')(x)\n",
        "        return x\n",
        "\n",
        "    def build_layer_structure(self, input_tensor):\n",
        "        x = input_tensor\n",
        "        input_res = input_layer\n",
        "\n",
        "        for d in range(self.depth):\n",
        "\n",
        "            x = self._inception_module(x)\n",
        "\n",
        "            if self.use_residual and d % 3 == 2:\n",
        "                x = self._shortcut_layer(input_tensor, x)\n",
        "                input_res = x\n",
        "\n",
        "        gap_layer = keras.layers.GlobalAveragePooling1D()(x)\n",
        "\n",
        "\n",
        "        return  gap_layer\n",
        "\n",
        "\n",
        "    def build_model(self, input_shape, nb_classes):\n",
        "        input_layer = keras.layers.Input(input_shape)\n",
        "\n",
        "        x = input_layer\n",
        "        input_res = input_layer\n",
        "\n",
        "        for d in range(self.depth):\n",
        "\n",
        "            x = self._inception_module(x)\n",
        "\n",
        "            if self.use_residual and d % 3 == 2:\n",
        "                x = self._shortcut_layer(input_res, x)\n",
        "                input_res = x\n",
        "\n",
        "        gap_layer = keras.layers.GlobalAveragePooling1D()(x)\n",
        "\n",
        "        output_layer = keras.layers.Dense(nb_classes, activation='softmax')(gap_layer)\n",
        "\n",
        "        model = keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "        model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(),\n",
        "                      metrics=['accuracy'])\n",
        "\n",
        "        reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.5, patience=50,\n",
        "                                                      min_lr=0.0001)\n",
        "\n",
        "        file_path = self.output_directory + 'best_model.hdf5'\n",
        "\n",
        "        model_checkpoint = keras.callbacks.ModelCheckpoint(filepath=file_path, monitor='loss',\n",
        "                                                           save_best_only=True)\n",
        "\n",
        "        self.callbacks = [reduce_lr, model_checkpoint]\n",
        "\n",
        "        return model\n",
        "\n",
        "    def fit(self, x_train, y_train, x_val, y_val, y_true, plot_test_acc=False):\n",
        "\n",
        "        # x_val and y_val are only used to monitor the test loss and NOT for training\n",
        "\n",
        "        if self.batch_size is None:\n",
        "            mini_batch_size = int(min(x_train.shape[0] / 10, 16))\n",
        "        else:\n",
        "            mini_batch_size = self.batch_size\n",
        "\n",
        "        start_time = time.time()\n",
        "\n",
        "        if plot_test_acc:\n",
        "\n",
        "            hist = self.model.fit(x_train, y_train, batch_size=mini_batch_size, epochs=self.nb_epochs,\n",
        "                                  verbose=self.verbose, validation_data=(x_val, y_val), callbacks=self.callbacks)\n",
        "        else:\n",
        "\n",
        "            hist = self.model.fit(x_train, y_train, batch_size=mini_batch_size, epochs=self.nb_epochs,\n",
        "                                  verbose=self.verbose, callbacks=self.callbacks)\n",
        "\n",
        "        duration = time.time() - start_time\n",
        "\n",
        "        self.model.save(self.output_directory + 'last_model.hdf5')\n",
        "\n",
        "        y_pred = self.predict(x_val, y_true, x_train, y_train, y_val)\n",
        "\n",
        "        # save predictions\n",
        "        np.save(self.output_directory + 'y_pred.npy', y_pred)\n",
        "\n",
        "        # convert the predicted from binary to integer\n",
        "        y_pred = np.argmax(y_pred, axis=1)\n",
        "\n",
        "        keras.backend.clear_session()\n",
        "\n",
        "        return hist\n",
        "\n",
        "    def predict(self, x_test, y_true, x_train, y_train, y_test):\n",
        "        start_time = time.time()\n",
        "        model_path = self.output_directory + 'best_model.hdf5'\n",
        "        model = keras.models.load_model(model_path)\n",
        "        y_pred = model.predict(x_test, batch_size=self.batch_size)\n",
        "        return y_pred"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOFMsxaTZK9V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "4f6c4486-76b4-4571-9924-00bcf1b5756e"
      },
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')\n",
        "# !ls \"/content/drive/My Drive\""
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxg9lgNhZBQJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd, numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from utils import *\n",
        "\n",
        "import importlib\n",
        "import utils\n",
        "importlib.reload(utils)\n",
        "from utils import *\n",
        "\n",
        "import yfinance as yf\n",
        "\n",
        "start = \"2018-01-01\"\n",
        "end   = \"2020-03-20\"\n",
        "\n",
        "bitcoin = False\n",
        "if not bitcoin:   \n",
        "    stocks = [\"TSLA\"]\n",
        "    keywords = {\"TSLA\": [\"Tesla\", \"Elon Musk\"]}\n",
        "else:    \n",
        "    stocks = [\"BTC-USD\"]\n",
        "    keywords = {\"BTC-USD\" : [\"Bitcoin\", \"Cryptocurrency\"] }\n",
        "\n",
        "df_financial = yf.download(stocks, \n",
        "                     #period = \"1Y\",\n",
        "                      start= start, \n",
        "                      end= end, \n",
        "                      progress=False)\n",
        "prices = df_financial[\"Close\"]\n",
        "prices = pd.DataFrame(data = prices, index = pd.date_range(start,end)).fillna(method = \"bfill\")\n",
        "\n",
        "df_bitcoin = pd.read_csv(\"/content/drive/My Drive/ColabData/articles_Bitcoin-Cryptocurrency_start=2019-01-01_end=2020-12-31.csv\", index_col = 0)\n",
        "# df_tesla = pd.read_csv(\"/content/drive/My Drive/ColabData/articles_Tesla-Elon_Musk_start=2019-01-01_end=2020-12-31.csv\", index_col = 0)\n",
        "df_tesla = pd.read_csv(\"/content/drive/My Drive/ColabData/Tesla | Elon Musk start:2018-01-01 end:2020-01-01.csv\", index_col = 0)\n",
        "\n",
        "df = df_bitcoin if bitcoin else df_tesla\n",
        "\n",
        "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification, AutoModelForSequenceClassification, TFBertForSequenceClassification \n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"nlptown/bert-base-multilingual-uncased-sentiment\")"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANUsWKn9qkGy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "2244a891-77ff-4569-9cc7-1ecf34439497"
      },
      "source": [
        "print (df)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     date_google  ...                                           maintext\n",
            "0     2018-01-01  ...  Click to email this to a friend (Opens in new ...\n",
            "1     2018-01-01  ...  Brain-computer interfaces could change the way...\n",
            "2     2018-01-01  ...  iStock / JJPan\\n2017 has been a year of data b...\n",
            "3     2018-01-01  ...  The increased plan by automobile companies to ...\n",
            "4     2018-01-01  ...  For Tesla CEO, Elon Musk, the year 2017 was qu...\n",
            "...          ...  ...                                                ...\n",
            "3453  2020-01-01  ...  Samuel Stebbins\\n24/7 Wall Street\\nThe United ...\n",
            "3454  2020-01-01  ...  In a heartwarming and impressive scene, Elon M...\n",
            "3455  2020-01-01  ...  Tesla CEO Elon Musk tweeted on Monday that he ...\n",
            "3456  2020-01-01  ...  Musk is no stranger to entertaining his 30-mil...\n",
            "3457  2020-01-01  ...  OK, I’ll admit it. I’ve got the best job on th...\n",
            "\n",
            "[3458 rows x 9 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caiPUUFkcEwe",
        "colab_type": "text"
      },
      "source": [
        "Split sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkbmlgJrcGmZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "68d5a071-7ace-4b3e-d91d-c589e2de1eab"
      },
      "source": [
        "main_text = False\n",
        "if main_text:\n",
        "    # main_text\n",
        "    text = df.maintext #pd.DataFrame(df.maintext.values, index = df[\"date_google\"]).dropna()\n",
        "    text.index = df[\"date_google\"]\n",
        "else:    \n",
        "    # titles and descriptions\n",
        "    titles = df.title\n",
        "    titles.index = df[\"date_google\"]\n",
        "    descriptions = df.description\n",
        "    descriptions.index = df[\"date_google\"]\n",
        "    text = pd.concat([titles,descriptions]).sort_index().dropna()\n",
        "    \n",
        "print(text.values[0])\n",
        "\n",
        "import nltk.data\n",
        "nltk.download('punkt')\n",
        "split_sentence_tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
        "\n",
        "split_sentences = text.apply(split_sentence_tokenizer.tokenize)\n",
        "split_sentences = split_sentences.groupby(split_sentences.index).sum()\n",
        "split_sentences = pd.DataFrame(split_sentences)\n",
        "\n",
        "df_ret = label_transformer(prices.copy(), shift = 1)  ### Here price start and end range takes effect.\n",
        "\n",
        "split_sentences, df_ret = series_intersection(split_sentences, df_ret)\n",
        "raw_sentences, raw_labels = generate_data_for_tokenizer(split_sentences,df_ret)\n",
        "\n",
        "lengths = raw_sentences.apply(lambda x: len(x[0].split()), axis = 1)\n",
        "sentences = raw_sentences[(lengths > 10) & (lengths < 120)] #filter short and long sentences\n",
        "\n",
        "labels = raw_labels[(lengths > 10) & (lengths < 120)]\n",
        "\n",
        "keywords_bitcoin = [\"crypto\", \"BTC\", \"bitcoin\", \"blockchain\"]\n",
        "keywords_tesla =   [\"tesla\", \"Elon\", \"Musk\", \"TSLA\", \"Tesla\"]\n",
        "keys = keywords_bitcoin if bitcoin else keywords_tesla\n",
        "raw_text = \"\".join(text.values).replace(\".com\",\"-com\").replace(\".\", \"\").replace(\",\", \"\").replace(\"\\n\", \" \").replace(\"-com\",\".com\")\n",
        "new_tokens = find_new_token_with_custom_keywords(raw_text, keys , 6, [])\n",
        "# new_tokens = new_tokens.append('tesla\\'s')\n",
        "\n",
        "print (new_tokens)\n",
        "print (sentences[0])\n",
        "print (sentences[0][19])\n",
        "\n",
        "print (sentences.dtypes)\n",
        "savedsentences = sentences\n",
        "\n",
        "res = [sub.replace('Tesla\\'s', 'tesla').replace('Tesla’s', 'tesla').replace('tesla\\'s', 'tesla').replace('tesla’s', 'tesla').replace('Teslas', 'tesla').replace('teslaelon', 'tesla').replace('musktesla', 'tesla') for sub in sentences[0]] \n",
        "\n",
        "# tesla’s Teslas\n",
        "\n",
        "sentences = pd.Series(res) \n",
        "print (sentences[19])\n",
        "print (sentences[103])\n",
        "\n",
        "# sentences = []\n",
        "# sentences.append(res)\n",
        "# print (sentences[0][19])\n",
        "# print (res[19])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Amber Heard and Elon Musk continue to rekindle their romance\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "New tokens to be added:  ['tesla', \"tesla's\", 'tesla’s', 'teslaelon', 'musktesla', 'teslas']\n",
            "['tesla', \"tesla's\", 'tesla’s', 'teslaelon', 'musktesla', 'teslas']\n",
            "2018-01-03    The Gigafactory is used to make battery cells ...\n",
            "2018-01-03    Elon Musk has been incredibly successful in ma...\n",
            "2018-01-03    Production of the electric-car maker’s mass-ma...\n",
            "2018-01-03    Elon Musk faces backlash for calling public tr...\n",
            "2018-01-03    In a few short sentences, Musk shows how to re...\n",
            "                                    ...                        \n",
            "2020-01-01    Elon Musk Takes a Jab at Ex-Nissan Head Carlos...\n",
            "2020-01-01    Santa Musk: Elon Musk Tweeted That He Was Work...\n",
            "2020-01-01    Elon Musk delivers New Year's Teslas with help...\n",
            "2020-01-01    Tesla CEO Elon Musk, Disney's Iger among 25 hi...\n",
            "2020-01-01    Musk is no stranger to entertaining his 30-mil...\n",
            "Name: 0, Length: 5247, dtype: object\n",
            "Tesla wasn't able to meet the Q4 2017 Model 3 production goals set by founder Elon Musk.\n",
            "0    object\n",
            "dtype: object\n",
            "Tesla wasn't able to meet the Q4 2017 Model 3 production goals set by founder Elon Musk.\n",
            "An architect, designer, and founder of the footwear brand United Nude, Dutch-born Rem D Koolhaas has a bone to pick with the modern car industry.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a77gW9KSd2od",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171,
          "referenced_widgets": [
            "4d10312afa314432b34e6931a5b8b95d",
            "461f09f8797c461ba448ad6a373eedba",
            "42843efcee0440099f4fd495944f31d1",
            "48d2620fb87e4ac08cea27421bb6308d",
            "278b89e1dd584b719ccc2aa9727ecf28",
            "482e80f0d1de4fd193a99d3300886011",
            "73288393ce85491da222790683a87509",
            "5815a1ebb7b94a60a88f7ca2439d16b0"
          ]
        },
        "outputId": "7585dec1-b4b1-4fcd-ea3f-22f06a59db54"
      },
      "source": [
        "#model = AutoModelForSequenceClassification.from_pretrained(\"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
        "model = TFAutoModelForSequenceClassification.from_pretrained(\"nlptown/bert-base-multilingual-uncased-sentiment\", from_pt=True)\n",
        "tokenizer.add_tokens(new_tokens)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4d10312afa314432b34e6931a5b8b95d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=669491321.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "All the weights of TFBertForSequenceClassification were initialized from the TF 2.0 model.\n",
            "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Os2JgdSeVsh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "d2d62d60-ff2a-4498-e59e-16a86d4e10d0"
      },
      "source": [
        "example = \"Bitcoin futures are trading below the cryptocurrency's spot price\"\n",
        "print(tokenizer.tokenize(example))\n",
        "example_ids = tokenizer.encode(example)\n",
        "print(example_ids)\n",
        "output = model.predict([example_ids]) \n",
        "print(\"    1 star     2 stars     3 stars     4 stars     5 stars\")\n",
        "print(output[0])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['bit', '##co', '##in', 'futures', 'are', 'trading', 'below', 'the', 'cry', '##pt', '##oc', '##urre', '##ncy', \"'\", 's', 'spot', 'price']\n",
            "[101, 16464, 10805, 10262, 42272, 10320, 34948, 16934, 10103, 29917, 15903, 20731, 46642, 19771, 112, 161, 24311, 16993, 102]\n",
            "    1 star     2 stars     3 stars     4 stars     5 stars\n",
            "[[ 1.1589032   0.6475529   0.23367804 -0.6871393  -1.1347752 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0-vmro8efP2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "f3742de2-23dc-40d9-f1c4-348644b8b107"
      },
      "source": [
        "example = \"I am so disappointed with this product\"\n",
        "print(tokenizer.tokenize(example))\n",
        "example_ids = tokenizer.encode(example)\n",
        "print(example_ids)\n",
        "output = model.predict([example_ids])\n",
        "print(\"    1 star     2 stars    3 stars    4 stars    5 stars\")\n",
        "print(output[0])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['i', 'am', 'so', 'disa', '##ppo', '##inted', 'with', 'this', 'product']\n",
            "[101, 151, 10345, 10297, 31021, 54894, 83912, 10171, 10372, 20058, 102]\n",
            "    1 star     2 stars    3 stars    4 stars    5 stars\n",
            "[[ 3.3838353  2.8609188  0.6469802 -2.6131783 -3.5148158]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTnZvF8p9fHD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "ea6980a2-3fec-44f6-95da-cdbb930732d4"
      },
      "source": [
        "example = \"Elon Musk's 'Blastar' would be a perfect addition to tesla Easter Eggs\"\n",
        "\n",
        "\n",
        "print(tokenizer.tokenize(example))\n",
        "example_ids = tokenizer.encode(example)\n",
        "print(example_ids)\n",
        "output = model.predict([example_ids])\n",
        "print(\"    1 star     2 stars    3 stars    4 stars    5 stars\")\n",
        "print(output[0])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['elo', '##n', 'mus', '##k', \"'\", 's', \"'\", 'blast', '##ar', \"'\", 'would', 'be', 'a', 'perfect', 'addition', 'to', 'tesla', 'easter', 'eggs']\n",
            "[101, 21834, 10115, 23139, 10167, 112, 161, 112, 47732, 10370, 112, 11008, 10346, 143, 23021, 15000, 10114, 51571, 58776, 48540, 102]\n",
            "    1 star     2 stars    3 stars    4 stars    5 stars\n",
            "[[-1.48236    -0.895975    0.41832617  1.1279131   0.57270813]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IksNea52Qwg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences = sentences.apply(lambda x : tokenizer.tokenize(x))"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBXhyvj6elaM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "outputId": "f0c6cd05-1803-41e0-d2e1-e79a59754556"
      },
      "source": [
        "encoded_sentences = sentences.apply(lambda x : tokenizer.encode(x))\n",
        "print (sentences)\n",
        "print (encoded_sentences)\n",
        "print (encoded_sentences[0])\n",
        "print (encoded_sentences[1])\n",
        "encoded_sentences.shape"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0       [the, gi, ##ga, ##fa, ##ctor, ##y, is, used, t...\n",
            "1       [elo, ##n, mus, ##k, has, been, inc, ##redi, #...\n",
            "2       [production, of, the, electric, -, car, maker,...\n",
            "3       [elo, ##n, mus, ##k, faces, back, ##lash, for,...\n",
            "4       [in, a, few, short, sentence, ##s, ,, mus, ##k...\n",
            "                              ...                        \n",
            "5242    [elo, ##n, mus, ##k, takes, a, ja, ##b, at, ex...\n",
            "5243    [santa, mus, ##k, :, elo, ##n, mus, ##k, twee,...\n",
            "5244    [elo, ##n, mus, ##k, deliver, ##s, new, year, ...\n",
            "5245    [tesla, ceo, elo, ##n, mus, ##k, ,, disney, ',...\n",
            "5246    [mus, ##k, is, no, stranger, to, enter, ##tain...\n",
            "Length: 5247, dtype: object\n",
            "0       [101, 10103, 21464, 10547, 13240, 35812, 10158...\n",
            "1       [101, 21834, 10115, 23139, 10167, 10438, 10662...\n",
            "2       [101, 11961, 10108, 10103, 15988, 118, 12485, ...\n",
            "3       [101, 21834, 10115, 23139, 10167, 31766, 11677...\n",
            "4       [101, 10104, 143, 13983, 12972, 45261, 10107, ...\n",
            "                              ...                        \n",
            "5242    [101, 21834, 10115, 23139, 10167, 18089, 143, ...\n",
            "5243    [101, 11257, 23139, 10167, 131, 21834, 10115, ...\n",
            "5244    [101, 21834, 10115, 23139, 10167, 68612, 10107...\n",
            "5245    [101, 51571, 23693, 21834, 10115, 23139, 10167...\n",
            "5246    [101, 23139, 10167, 10127, 10181, 46858, 10114...\n",
            "Length: 5247, dtype: object\n",
            "[101, 10103, 21464, 10547, 13240, 35812, 10158, 10127, 11173, 10114, 12696, 34794, 22596, 10110, 15834, 13541, 15832, 10139, 51571, 15988, 20509, 119, 102]\n",
            "[101, 21834, 10115, 23139, 10167, 10438, 10662, 13565, 83887, 28634, 17409, 10104, 11260, 12850, 20532, 10110, 10649, 10108, 10203, 10127, 12090, 10114, 12548, 10191, 83903, 119, 102]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5247,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gy6dMkyPiDLZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 768
        },
        "outputId": "19a26859-c484-4be2-9f33-6cac31db432a"
      },
      "source": [
        "# if we have \"tesla's\", we failed\n",
        "\n",
        "# print (encoded_sentences[0])\n",
        "# print (model.predict([encoded_sentences[0]]))\n",
        "# print (model.predict([encoded_sentences[0]])[0])\n",
        "\n",
        "# print (sentences[0][3])\n",
        "# print (sentences[0][4])\n",
        "# print (sentences[0][5])\n",
        "# print (sentences[0][6])\n",
        "# print (sentences[0][7])\n",
        "# print (sentences[0][9])\n",
        "# print (sentences[0][10])\n",
        "# print (sentences[0][16])\n",
        "# print (sentences[0][17])\n",
        "# print (sentences[0][18])\n",
        "# print (sentences[0][19])\n",
        "# print (sentences[0][20])\n",
        "\n",
        "# print (sentences[0][18])\n",
        "# print (encoded_sentences[18])\n",
        "# print (model.predict([encoded_sentences[18]]))\n",
        "# print (model.predict([encoded_sentences[18]])[0])\n",
        "\n",
        "print (sentences[10])\n",
        "print (encoded_sentences[10])\n",
        "print (model.predict(encoded_sentences[10]))\n",
        "print (model.predict([encoded_sentences[10]])[0])\n",
        "\n",
        "print (sentences[19])\n",
        "print (encoded_sentences[19])\n",
        "print (model.predict([encoded_sentences[19]]))\n",
        "print (model.predict([encoded_sentences[19]])[0])\n",
        "\n",
        "# for i in range(1, len(encoded_sentences)): \n",
        "\n",
        "#     print (i)\n",
        "#     print (sentences[i])\n",
        "#     print(encoded_sentences[i]) \n",
        "#     output = model.predict([encoded_sentences[i]])[0]\n",
        "#     print (output)\n",
        "\n",
        "\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['it', 'becomes', 'pretty', 'difficult', 'to', 'manage', 'time', 'when', 'you', 'are', 'managing', 'companies', 'like', 'tesla', ',', 'space', '##x', ',', 'solar', '##city', ',', 'the', 'bor', '##ing', 'company', ',', 'neural', '##ink', 'all', 'by', 'yourself', '.']\n",
            "[101, 10197, 23259, 31897, 24952, 10114, 54871, 10573, 10704, 10855, 10320, 42737, 17810, 11531, 51571, 117, 12732, 10661, 117, 17195, 48940, 117, 10103, 22001, 10285, 11062, 117, 86165, 67584, 10367, 10151, 48906, 119, 102]\n",
            "(array([[ 0.21061476,  0.25646615,  0.13912632, -0.26722145, -0.16550466],\n",
            "       [-0.39651543,  0.07019208,  0.51037955,  0.0436032 , -0.24164432],\n",
            "       [ 0.01891482,  0.15200277,  0.20495693, -0.14572652, -0.08241742],\n",
            "       [-0.00224372,  0.2066065 ,  0.24290684, -0.16276857, -0.1285699 ],\n",
            "       [ 0.2184724 ,  0.26466143,  0.13755997, -0.27396998, -0.17589429],\n",
            "       [ 0.08456489,  0.21876645,  0.19301142, -0.21220122, -0.14421716],\n",
            "       [-0.00769654,  0.23896077,  0.26609454, -0.17968746, -0.13513443],\n",
            "       [ 0.18241844,  0.24849148,  0.14379375, -0.26618928, -0.14733319],\n",
            "       [ 0.10596564,  0.2107661 ,  0.19716267, -0.21343203, -0.13338877],\n",
            "       [-0.7360888 , -0.23030877,  0.5427744 ,  0.40979818, -0.01786993],\n",
            "       [-0.6916159 , -0.18494348,  0.5522722 ,  0.33937955,  0.02254352],\n",
            "       [-0.15169439,  0.23435824,  0.3430247 , -0.13467608, -0.08601702],\n",
            "       [-1.128241  , -0.19971149,  0.5543359 ,  0.4264346 ,  0.31116873],\n",
            "       [ 0.20852046,  0.26476118,  0.15169433, -0.26984155, -0.17495619],\n",
            "       [-0.42950067, -0.13893385,  0.4354795 ,  0.2101009 ,  0.00970723],\n",
            "       [ 0.21255621,  0.26369834,  0.1414115 , -0.27148145, -0.16897306],\n",
            "       [ 0.1649273 ,  0.24348322,  0.14936058, -0.2570922 , -0.14578189],\n",
            "       [ 0.21640173,  0.26444608,  0.13962066, -0.27419093, -0.16780278],\n",
            "       [ 0.21255621,  0.26369834,  0.1414115 , -0.27148145, -0.16897306],\n",
            "       [ 0.16979511,  0.2528154 ,  0.16161396, -0.2567252 , -0.15952495],\n",
            "       [-0.6545954 , -0.149192  ,  0.4106427 ,  0.2823746 ,  0.17283833],\n",
            "       [ 0.21255621,  0.26369834,  0.1414115 , -0.27148145, -0.16897306],\n",
            "       [ 0.21305946,  0.25926042,  0.14089642, -0.27242574, -0.16787536],\n",
            "       [ 0.2379505 ,  0.27487084,  0.13437615, -0.28753522, -0.180974  ],\n",
            "       [-0.11250585,  0.15165134,  0.30559248, -0.088303  , -0.12694561],\n",
            "       [-0.8759406 , -0.42922813,  0.3771903 ,  0.44542322,  0.49654326],\n",
            "       [ 0.21255621,  0.26369834,  0.1414115 , -0.27148145, -0.16897306],\n",
            "       [-0.04807852,  0.4871113 ,  0.41063282, -0.10168093, -0.77934223],\n",
            "       [ 0.15899366,  0.22658932,  0.16662554, -0.25050464, -0.13870311],\n",
            "       [ 0.07263787,  0.20034637,  0.19377144, -0.20288113, -0.12564589],\n",
            "       [ 0.20759892,  0.26607627,  0.15176968, -0.27779654, -0.16838728],\n",
            "       [ 0.11893062,  0.21529163,  0.1691431 , -0.21845654, -0.14057398],\n",
            "       [ 0.16986108,  0.23905386,  0.16105022, -0.24364756, -0.15480852],\n",
            "       [-0.10104806,  0.08343737,  0.21306346, -0.09357473, -0.01834354]],\n",
            "      dtype=float32),)\n",
            "[[ 1.0543495  2.1427898  1.6134409 -1.1144563 -3.0474207]]\n",
            "['tesla', 'wasn', \"'\", 't', 'able', 'to', 'meet', 'the', 'q', '##4', '2017', 'model', '3', 'production', 'goals', 'set', 'by', 'founder', 'elo', '##n', 'mus', '##k', '.']\n",
            "[101, 51571, 54880, 112, 162, 16368, 10114, 19508, 10103, 159, 11124, 10294, 10713, 124, 11961, 17707, 10486, 10151, 21323, 21834, 10115, 23139, 10167, 119, 102]\n",
            "(array([[ 0.9987128 ,  1.3307008 ,  0.82579374, -0.76544935, -1.9403753 ]],\n",
            "      dtype=float32),)\n",
            "[[ 0.9987128   1.3307008   0.82579374 -0.76544935 -1.9403753 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EL49QLltqP-G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = encoded_sentences.apply(lambda x : model.predict([x])[0])\n",
        "\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHEXNTYyqlEn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "8218836e-1db6-4ae9-93ba-fbc4c3888b0d"
      },
      "source": [
        "print (predictions)\n",
        "print (predictions[0])\n",
        "print (predictions[1][0])\n",
        "\n",
        "rows_list = []\n",
        "for i in range(len(predictions)): \n",
        "\n",
        "        rows_list.append(predictions[i][0])\n",
        "\n",
        "predictions_2 = pd.DataFrame(rows_list) \n",
        "predictions_2.set_index(savedsentences.index, inplace=True)\n",
        "print (predictions_2)\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0       [[-1.5878555, -1.2169515, 0.0580857, 1.1024681...\n",
            "1       [[-2.017963, -1.4857517, 0.023057202, 1.343017...\n",
            "2       [[0.4503634, 0.9695554, 0.7167253, -0.45672438...\n",
            "3       [[0.74593663, 0.5283271, 0.2505643, -0.2185801...\n",
            "4       [[-2.7147396, -1.3509377, 1.016764, 1.9489738,...\n",
            "                              ...                        \n",
            "5242    [[0.22119078, -0.09615827, 0.030674858, 0.0729...\n",
            "5243    [[-0.43458158, -0.404484, 0.24592908, 0.508108...\n",
            "5244    [[-1.892945, -1.6775222, 0.076644175, 1.496820...\n",
            "5245    [[-0.037779473, -1.0146422, -0.8597988, -0.155...\n",
            "5246    [[-0.34351206, 0.15970682, 0.4847481, 0.361807...\n",
            "Length: 5247, dtype: object\n",
            "[[-1.5878555 -1.2169515  0.0580857  1.1024681  1.238524 ]]\n",
            "[-2.017963  -1.4857517  0.0230572  1.3430179  1.6998396]\n",
            "                   0         1         2         3         4\n",
            "2018-01-03 -1.587855 -1.216951  0.058086  1.102468  1.238524\n",
            "2018-01-03 -2.017963 -1.485752  0.023057  1.343018  1.699840\n",
            "2018-01-03  0.450363  0.969555  0.716725 -0.456724 -1.358472\n",
            "2018-01-03  0.745937  0.528327  0.250564 -0.218580 -1.085376\n",
            "2018-01-03 -2.714740 -1.350938  1.016764  1.948974  0.704865\n",
            "...              ...       ...       ...       ...       ...\n",
            "2020-01-01  0.221191 -0.096158  0.030675  0.072951 -0.276444\n",
            "2020-01-01 -0.434582 -0.404484  0.245929  0.508108 -0.040123\n",
            "2020-01-01 -1.892945 -1.677522  0.076644  1.496821  1.474153\n",
            "2020-01-01 -0.037779 -1.014642 -0.859799 -0.155277  1.966616\n",
            "2020-01-01 -0.343512  0.159707  0.484748  0.361807 -0.553452\n",
            "\n",
            "[5247 rows x 5 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKUHsrxCSVAp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "# predictions_2 = predictions.copy().to_frame()\n",
        "# predictions_2.set_index(savedsentences.index, inplace=True)\n",
        "# print (predictions_2)\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhsKGHxButHf",
        "colab_type": "text"
      },
      "source": [
        "# Here we should get the average stars for each transaction day."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VxnQbSXSaee",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "avg_predictions = predictions_2.groupby(predictions_2.index).apply(np.mean)\n",
        "avg_predictions_array = np.array([a for a in avg_predictions.values])\n",
        "shape = avg_predictions_array.shape\n",
        "pd.to_pickle(avg_predictions, \"sentiment_predictions_tesla_with_tokens\")"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnNMGmJ_Sd2m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "7b23f07c-b38b-4a0b-cd48-ebf87d663f07"
      },
      "source": [
        "avg_predictions.shape\n",
        "\n",
        "\n",
        "avg_predictions.columns = ['1star', '2star','3star', '4star','5star']\n",
        "\n",
        "print (avg_predictions)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               1star     2star     3star     4star     5star\n",
            "2018-01-03 -0.839789 -0.449200  0.338388  0.678618  0.155123\n",
            "2018-01-04 -0.370741  0.125653  0.366977  0.134753 -0.328072\n",
            "2018-01-05 -0.127998 -0.158626 -0.021847  0.107146  0.113772\n",
            "2018-01-06 -0.243374 -0.300769  0.110360  0.364268  0.078938\n",
            "2018-01-07 -0.341203 -0.274074  0.119858  0.332447  0.101550\n",
            "...              ...       ...       ...       ...       ...\n",
            "2019-12-28 -0.822621 -0.634629  0.039574  0.659956  0.478049\n",
            "2019-12-29 -0.565735 -0.246549  0.384767  0.451289 -0.127899\n",
            "2019-12-30  0.138386  0.088470  0.155829  0.033351 -0.416246\n",
            "2019-12-31 -0.527490 -0.391058  0.180313  0.529687  0.053875\n",
            "2020-01-01 -0.585835 -0.696162 -0.072604  0.488492  0.691748\n",
            "\n",
            "[717 rows x 5 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znzIqbmZAGwf",
        "colab_type": "text"
      },
      "source": [
        "# Here I should link the tesla stock data, and its associated date. Using the above features to do the predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPJfvD7ru9EV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "cc77f5fb-2ff1-4e9f-b653-fee996112eac"
      },
      "source": [
        "import yfinance as yf\n",
        "tickers = ['TSLA']\n",
        "ohlc = yf.download(tickers, start=\"2018-01-01\", end=\"2020-03-20\")\n",
        "print(list(ohlc.columns.values))\n",
        "#ohlc.head()\n",
        "ohlc_reversed = ohlc.sort_values(['Date'], ascending=[False])\n",
        "ohlc_reversed = ohlc_reversed.reindex(columns=['Open', 'High', 'Low', 'Volume','Adj Close', 'Close'])\n",
        "ohlc_reversed.drop('Adj Close', axis=1, inplace=True)\n",
        "print (ohlc_reversed)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n",
            "['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']\n",
            "                  Open        High         Low    Volume       Close\n",
            "Date                                                                \n",
            "2020-03-19  374.700012  452.000000  358.459991  30195500  427.640015\n",
            "2020-03-18  389.000000  404.859985  350.510010  23786200  361.220001\n",
            "2020-03-17  440.010010  471.850006  396.000000  23994600  430.200012\n",
            "2020-03-16  469.500000  494.869995  442.170013  20489500  445.070007\n",
            "2020-03-13  595.000000  607.570007  502.000000  22640300  546.619995\n",
            "...                ...         ...         ...       ...         ...\n",
            "2018-01-08  316.000000  337.019989  315.500000   9859400  336.410004\n",
            "2018-01-05  316.619995  317.239990  312.000000   4591200  316.579987\n",
            "2018-01-04  312.869995  318.549988  305.679993   9946300  314.619995\n",
            "2018-01-03  321.000000  325.250000  315.549988   4521500  317.250000\n",
            "2018-01-02  312.000000  322.109985  311.000000   4352200  320.529999\n",
            "\n",
            "[557 rows x 5 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKXdElDkB0gU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "fb4ba86c-7af4-44ea-9a0e-6183d70a087b"
      },
      "source": [
        "df = ohlc_reversed.merge(avg_predictions, left_index=True, right_index=True)\n",
        "df = df.reindex(columns=['1star' ,'2star' ,'3star', '4star','5star' ,'Open', 'High', 'Low', 'Volume', 'Close'])\n",
        "\n",
        "df = df.iloc[17:]\n",
        "print (df)\n",
        "df.head()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               1star     2star     3star  ...         Low   Volume       Close\n",
            "2019-12-05  0.644248  0.228350  0.090177  ...  327.250000  3724600  330.369995\n",
            "2019-12-04  0.613230  0.238537  0.144929  ...  332.850006  5533000  333.029999\n",
            "2019-12-03  0.900305  0.352730  0.025787  ...  332.190002  6573700  336.200012\n",
            "2019-11-29  0.726176  0.507032 -0.054036  ...  327.500000  2465600  329.940002\n",
            "2019-11-27  0.684971  0.461064  0.135136  ...  328.570007  5555600  331.290009\n",
            "...              ...       ...       ...  ...         ...      ...         ...\n",
            "2018-01-09 -0.112247 -0.303341  0.051899  ...  327.399994  7146600  333.690002\n",
            "2018-01-08 -0.062443 -0.098385  0.142120  ...  315.500000  9859400  336.410004\n",
            "2018-01-05 -0.127998 -0.158626 -0.021847  ...  312.000000  4591200  316.579987\n",
            "2018-01-04 -0.370741  0.125653  0.366977  ...  305.679993  9946300  314.619995\n",
            "2018-01-03 -0.839789 -0.449200  0.338388  ...  315.549988  4521500  317.250000\n",
            "\n",
            "[478 rows x 10 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1star</th>\n",
              "      <th>2star</th>\n",
              "      <th>3star</th>\n",
              "      <th>4star</th>\n",
              "      <th>5star</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Close</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2019-12-05</th>\n",
              "      <td>0.644248</td>\n",
              "      <td>0.228350</td>\n",
              "      <td>0.090177</td>\n",
              "      <td>-0.148616</td>\n",
              "      <td>-0.652239</td>\n",
              "      <td>332.829987</td>\n",
              "      <td>334.420013</td>\n",
              "      <td>327.250000</td>\n",
              "      <td>3724600</td>\n",
              "      <td>330.369995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-12-04</th>\n",
              "      <td>0.613230</td>\n",
              "      <td>0.238537</td>\n",
              "      <td>0.144929</td>\n",
              "      <td>-0.137245</td>\n",
              "      <td>-0.715586</td>\n",
              "      <td>337.750000</td>\n",
              "      <td>337.859985</td>\n",
              "      <td>332.850006</td>\n",
              "      <td>5533000</td>\n",
              "      <td>333.029999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-12-03</th>\n",
              "      <td>0.900305</td>\n",
              "      <td>0.352730</td>\n",
              "      <td>0.025787</td>\n",
              "      <td>-0.326992</td>\n",
              "      <td>-0.771402</td>\n",
              "      <td>332.619995</td>\n",
              "      <td>337.910004</td>\n",
              "      <td>332.190002</td>\n",
              "      <td>6573700</td>\n",
              "      <td>336.200012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-11-29</th>\n",
              "      <td>0.726176</td>\n",
              "      <td>0.507032</td>\n",
              "      <td>-0.054036</td>\n",
              "      <td>-0.318549</td>\n",
              "      <td>-0.729484</td>\n",
              "      <td>331.109985</td>\n",
              "      <td>331.260010</td>\n",
              "      <td>327.500000</td>\n",
              "      <td>2465600</td>\n",
              "      <td>329.940002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-11-27</th>\n",
              "      <td>0.684971</td>\n",
              "      <td>0.461064</td>\n",
              "      <td>0.135136</td>\n",
              "      <td>-0.290872</td>\n",
              "      <td>-0.808071</td>\n",
              "      <td>331.119995</td>\n",
              "      <td>333.929993</td>\n",
              "      <td>328.570007</td>\n",
              "      <td>5555600</td>\n",
              "      <td>331.290009</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               1star     2star     3star  ...         Low   Volume       Close\n",
              "2019-12-05  0.644248  0.228350  0.090177  ...  327.250000  3724600  330.369995\n",
              "2019-12-04  0.613230  0.238537  0.144929  ...  332.850006  5533000  333.029999\n",
              "2019-12-03  0.900305  0.352730  0.025787  ...  332.190002  6573700  336.200012\n",
              "2019-11-29  0.726176  0.507032 -0.054036  ...  327.500000  2465600  329.940002\n",
              "2019-11-27  0.684971  0.461064  0.135136  ...  328.570007  5555600  331.290009\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJmqFaKhHNNU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# #### Only use stock data, no news features.\n",
        "\n",
        "# df = ohlc_reversed\n",
        "\n",
        "# print (df)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sawpGuZgCMLC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def standard_scaler(X_train, X_test):\n",
        "    train_samples, train_nx, train_ny = X_train.shape\n",
        "    test_samples, test_nx, test_ny = X_test.shape\n",
        "    \n",
        "    X_train = X_train.reshape((train_samples, train_nx * train_ny))\n",
        "    X_test = X_test.reshape((test_samples, test_nx * test_ny))\n",
        "    \n",
        "    preprocessor = prep.StandardScaler().fit(X_train)\n",
        "    X_train = preprocessor.transform(X_train)\n",
        "    X_test = preprocessor.transform(X_test)\n",
        "    \n",
        "    X_train = X_train.reshape((train_samples, train_nx, train_ny))\n",
        "    X_test = X_test.reshape((test_samples, test_nx, test_ny))\n",
        "    \n",
        "    return X_train, X_test\n",
        "\n",
        "def preprocess_data(stock, seq_len):\n",
        "    amount_of_features = len(stock.columns)\n",
        "    data = stock.values\n",
        "    \n",
        "    sequence_length = seq_len + 1\n",
        "    result = []\n",
        "    ## Probably here add another column as the label.\n",
        "    for index in range(len(data) - sequence_length):\n",
        "        result.append(data[index : index + sequence_length])\n",
        "        \n",
        "    result = np.array(result)\n",
        "    row = round(0.9 * result.shape[0])\n",
        "    train = result[: int(row), :]\n",
        "\n",
        "    # print (result)\n",
        "    # print (row)\n",
        "    print (train[:, : -1])\n",
        "    print (train[:, -1][: ,-1]) \n",
        "\n",
        "    print (result[int(row) :, -1][ : ,-1]) \n",
        "\n",
        "    train, result = standard_scaler(train, result)\n",
        "    \n",
        "    X_train = train[:, : -1]\n",
        "    y_train = train[:, -1][: ,-1]\n",
        "    X_test = result[int(row) :, : -1]\n",
        "    y_test = result[int(row) :, -1][ : ,-1]\n",
        "\n",
        "    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], amount_of_features))\n",
        "    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], amount_of_features)) \n",
        "\n",
        " \n",
        "\n",
        "    return [X_train, y_train, X_test, y_test]\n",
        "\n",
        "def build_model(layers):\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(512, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(LSTM(256, return_sequences=True))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(LSTM(128, return_sequences=True))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(LSTM(64, return_sequences=True))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(LSTM(32))\n",
        "    model.add(Dense(1, activation='linear'))\n",
        "\n",
        "    start = time.time()\n",
        "    model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
        "    model.summary() \n",
        "    print(\"Compilation Time : \", time.time() - start)\n",
        "    return model\n",
        "\n"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SgsiEFVjCYq_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "907c08ee-a3c0-43b4-ccf1-4e1bd3514225"
      },
      "source": [
        "import time\n",
        "import math\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Activation\n",
        "from keras.layers.recurrent import LSTM\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn.preprocessing as prep\n",
        "\n",
        "window = 15\n",
        "X_train, y_train, X_test, y_test = preprocess_data(df[:: -1], window)\n",
        "print(\"X_train\", X_train.shape)\n",
        "print(\"y_train\", y_train.shape)\n",
        "print(\"X_test\", X_test.shape)\n",
        "print(\"y_test\", y_test.shape)\n",
        "# print (X_train)\n",
        "# print (y_train)\n",
        "# print (X_test)\n",
        "# print (y_test)\n",
        "\n",
        "model = build_model([X_train.shape[2], window, 100, 1])"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[-8.39788820e-01 -4.49199634e-01  3.38387726e-01 ...  3.15549988e+02\n",
            "    4.52150000e+06  3.17250000e+02]\n",
            "  [-3.70741240e-01  1.25653438e-01  3.66977357e-01 ...  3.05679993e+02\n",
            "    9.94630000e+06  3.14619995e+02]\n",
            "  [-1.27997957e-01 -1.58625625e-01 -2.18474703e-02 ...  3.12000000e+02\n",
            "    4.59120000e+06  3.16579987e+02]\n",
            "  ...\n",
            "  [-1.06034684e+00 -8.90969903e-01 -4.71240461e-02 ...  3.49200012e+02\n",
            "    6.21040000e+06  3.51559998e+02]\n",
            "  [ 2.82728991e-02 -4.43000287e-01 -3.18683939e-01 ...  3.51000000e+02\n",
            "    5.46540000e+06  3.52790009e+02]\n",
            "  [-1.35894399e+00 -9.97006757e-01 -2.25197513e-02 ...  3.43519989e+02\n",
            "    5.28750000e+06  3.45890015e+02]]\n",
            "\n",
            " [[-3.70741240e-01  1.25653438e-01  3.66977357e-01 ...  3.05679993e+02\n",
            "    9.94630000e+06  3.14619995e+02]\n",
            "  [-1.27997957e-01 -1.58625625e-01 -2.18474703e-02 ...  3.12000000e+02\n",
            "    4.59120000e+06  3.16579987e+02]\n",
            "  [-6.24429317e-02 -9.83847070e-02  1.42120239e-01 ...  3.15500000e+02\n",
            "    9.85940000e+06  3.36410004e+02]\n",
            "  ...\n",
            "  [ 2.82728991e-02 -4.43000287e-01 -3.18683939e-01 ...  3.51000000e+02\n",
            "    5.46540000e+06  3.52790009e+02]\n",
            "  [-1.35894399e+00 -9.97006757e-01 -2.25197513e-02 ...  3.43519989e+02\n",
            "    5.28750000e+06  3.45890015e+02]\n",
            "  [ 4.11874902e-01  3.23055619e-01  2.68139952e-01 ...  3.36399994e+02\n",
            "    6.74030000e+06  3.37640015e+02]]\n",
            "\n",
            " [[-1.27997957e-01 -1.58625625e-01 -2.18474703e-02 ...  3.12000000e+02\n",
            "    4.59120000e+06  3.16579987e+02]\n",
            "  [-6.24429317e-02 -9.83847070e-02  1.42120239e-01 ...  3.15500000e+02\n",
            "    9.85940000e+06  3.36410004e+02]\n",
            "  [-1.12246628e-01 -3.03340668e-01  5.18991910e-02 ...  3.27399994e+02\n",
            "    7.14660000e+06  3.33690002e+02]\n",
            "  ...\n",
            "  [-1.35894399e+00 -9.97006757e-01 -2.25197513e-02 ...  3.43519989e+02\n",
            "    5.28750000e+06  3.45890015e+02]\n",
            "  [ 4.11874902e-01  3.23055619e-01  2.68139952e-01 ...  3.36399994e+02\n",
            "    6.74030000e+06  3.37640015e+02]\n",
            "  [ 1.52387127e-01  1.37819682e-01  2.62977962e-01 ...  3.35709991e+02\n",
            "    4.53940000e+06  3.42850006e+02]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 3.01853336e-01  2.29865391e-01  2.19914116e-01 ...  2.19210007e+02\n",
            "    5.76100000e+06  2.20679993e+02]\n",
            "  [-2.62481372e-01 -1.83134383e-01  1.37443968e-01 ...  2.20850006e+02\n",
            "    7.39530000e+06  2.29580002e+02]\n",
            "  [-5.63932508e-01 -5.94835535e-01 -5.97662407e-02 ...  2.25169998e+02\n",
            "    4.18940000e+06  2.27449997e+02]\n",
            "  ...\n",
            "  [-3.21867920e-01 -4.84522276e-01  3.48711829e-03 ...  2.38160004e+02\n",
            "    6.35300000e+06  2.40619995e+02]\n",
            "  [-3.45622867e-01 -1.99084720e-01  2.41454962e-01 ...  2.39220001e+02\n",
            "    4.34020000e+06  2.41229996e+02]\n",
            "  [ 5.71637634e-02 -2.83871426e-01 -1.23223952e-01 ...  2.22610001e+02\n",
            "    1.28915000e+07  2.23210007e+02]]\n",
            "\n",
            " [[-2.62481372e-01 -1.83134383e-01  1.37443968e-01 ...  2.20850006e+02\n",
            "    7.39530000e+06  2.29580002e+02]\n",
            "  [-5.63932508e-01 -5.94835535e-01 -5.97662407e-02 ...  2.25169998e+02\n",
            "    4.18940000e+06  2.27449997e+02]\n",
            "  [ 9.07152104e-02  3.10952056e-01  4.78744720e-01 ...  2.29229996e+02\n",
            "    4.80270000e+06  2.31789993e+02]\n",
            "  ...\n",
            "  [-3.45622867e-01 -1.99084720e-01  2.41454962e-01 ...  2.39220001e+02\n",
            "    4.34020000e+06  2.41229996e+02]\n",
            "  [ 5.71637634e-02 -2.83871426e-01 -1.23223952e-01 ...  2.22610001e+02\n",
            "    1.28915000e+07  2.23210007e+02]\n",
            "  [-3.92396402e-01 -3.44235241e-01  1.38307135e-01 ...  2.18360001e+02\n",
            "    9.42710000e+06  2.28699997e+02]]\n",
            "\n",
            " [[-5.63932508e-01 -5.94835535e-01 -5.97662407e-02 ...  2.25169998e+02\n",
            "    4.18940000e+06  2.27449997e+02]\n",
            "  [ 9.07152104e-02  3.10952056e-01  4.78744720e-01 ...  2.29229996e+02\n",
            "    4.80270000e+06  2.31789993e+02]\n",
            "  [-6.84925765e-01 -6.43540382e-01 -7.45040411e-03 ...  2.28940002e+02\n",
            "    4.88370000e+06  2.35539993e+02]\n",
            "  ...\n",
            "  [ 5.71637634e-02 -2.83871426e-01 -1.23223952e-01 ...  2.22610001e+02\n",
            "    1.28915000e+07  2.23210007e+02]\n",
            "  [-3.92396402e-01 -3.44235241e-01  1.38307135e-01 ...  2.18360001e+02\n",
            "    9.42710000e+06  2.28699997e+02]\n",
            "  [-1.15754224e+00 -6.53974324e-01  1.26645194e-01 ...  2.27399994e+02\n",
            "    1.18845000e+07  2.42559998e+02]]]\n",
            "[337.64001465 342.8500061  349.52999878 345.82000732 354.30999756\n",
            " 349.25       343.75       333.13000488 333.97000122 345.\n",
            " 315.23001099 310.42001343 315.73001099 323.66000366 322.30999756\n",
            " 334.07000732 335.48999023 334.76998901 333.29998779 346.17001343\n",
            " 352.04998779 357.42001343 350.98999023 343.05999756 330.92999268\n",
            " 335.11999512 333.3500061  328.20001221 332.29998779 329.1000061\n",
            " 327.17001343 345.51000977 341.83999634 326.63000488 325.6000061\n",
            " 321.3500061  310.54998779 316.52999878 309.1000061  301.54000854\n",
            " 304.17999268 279.17999268 257.77999878 266.13000488 252.47999573\n",
            " 267.52999878 286.94000244 305.72000122 299.29998779 289.66000366\n",
            " 304.70001221 300.92999268 294.07998657 300.33999634 291.20999146\n",
            " 287.69000244 293.3500061  300.07998657 290.23999023 283.36999512\n",
            " 283.45999146 280.69000244 285.48001099 294.07998657 293.8999939\n",
            " 301.1499939  284.45001221 294.08999634 302.76998901 301.97000122\n",
            " 306.8500061  305.01998901 301.05999756 291.97000122 284.17999268\n",
            " 286.48001099 284.54000854 276.82000732 284.48999023 275.01000977\n",
            " 279.07000732 277.8500061  278.8500061  283.76000977 291.72000122\n",
            " 284.73001099 291.82000732 296.73999023 291.13000488 319.5\n",
            " 316.08999634 317.66000366 332.1000061  342.76998901 344.77999878\n",
            " 357.72000122 358.17001343 370.82998657 352.54998779 362.22000122\n",
            " 347.51000977 333.63000488 333.01000977 342.         344.5\n",
            " 349.92999268 342.95001221 335.07000732 310.85998535 309.16000366\n",
            " 308.8999939  318.51000977 322.47000122 318.95999146 316.70999146\n",
            " 318.86999512 310.1000061  322.69000244 323.8500061  320.23001099\n",
            " 313.57998657 303.20001221 297.42999268 308.73999023 306.6499939\n",
            " 290.17001343 298.14001465 300.83999634 349.54000854 348.17001343\n",
            " 341.98999023 379.57000732 370.33999634 352.45001221 355.48999023\n",
            " 356.41000366 347.64001465 338.69000244 335.45001221 305.5\n",
            " 308.44000244 321.8999939  321.64001465 320.1000061  322.82000732\n",
            " 319.26998901 311.85998535 305.01000977 303.1499939  301.66000366\n",
            " 288.95001221 280.73999023 280.95001221 263.23999023 285.5\n",
            " 279.44000244 290.54000854 289.45999146 295.20001221 294.83999634\n",
            " 284.95999146 299.01998901 298.32998657 299.1000061  299.67999268\n",
            " 300.98999023 309.57998657 307.51998901 264.76998901 310.70001221\n",
            " 301.01998901 294.79998779 281.82998657 261.95001221 250.55999756\n",
            " 262.79998779 256.88000488 252.22999573 258.77999878 259.58999634\n",
            " 276.58999634 271.77999878 263.91000366 260.         260.95001221\n",
            " 294.14001465 288.5        314.85998535 330.8999939  334.8500061\n",
            " 329.8999939  337.32000732 344.27999878 346.41000366 341.3999939\n",
            " 341.05999756 348.16000366 351.3999939  350.51000977 331.27999878\n",
            " 338.73001099 344.         348.44000244 354.30999756 353.47000122\n",
            " 347.48999023 338.19000244 325.82998657 346.         343.92001343\n",
            " 347.86999512 341.17001343 350.48001099 358.48999023 359.70001221\n",
            " 363.05999756 357.97000122 365.1499939  366.76000977 366.6000061\n",
            " 376.79000854 365.70999146 348.42001343 337.02999878 332.97000122\n",
            " 315.38000488 319.76998901 295.39001465 326.08999634 316.13000488\n",
            " 333.86999512 332.79998779 310.11999512 300.35998535 317.69000244\n",
            " 334.95999146 335.3500061  338.52999878 344.97000122 347.26000977\n",
            " 334.3999939  344.42999268 346.04998779 347.30999756 302.26000977\n",
            " 298.92001343 287.58999634 291.51000977 297.04000854 296.38000488\n",
            " 297.45999146 308.76998901 307.01998901 312.20999146 312.89001465\n",
            " 321.3500061  317.22000122 307.51000977 305.79998779 312.83999634\n",
            " 311.80999756 308.17001343 303.76998901 307.88000488 305.64001465\n",
            " 302.55999756 291.23001099 294.70999146 298.76998901 297.85998535\n",
            " 314.73999023 319.88000488 294.79000854 285.35998535 276.54000854\n",
            " 276.23999023 276.58999634 284.14001465 290.92001343 283.35998535\n",
            " 288.95999146 289.95999146 275.42999268 267.47000122 273.6000061\n",
            " 274.01998901 264.52999878 260.42001343 267.76998901 274.82998657\n",
            " 278.61999512 279.85998535 289.17999268 285.88000488 291.80999756\n",
            " 267.77999878 274.95999146 273.20001221 272.30999756 276.05999756\n",
            " 268.42001343 267.70001221 266.38000488 273.35998535 271.23001099\n",
            " 273.26000977 262.75       263.8999939  258.66000366 247.63000488\n",
            " 241.47000122 238.69000244 244.1000061  255.02999878 255.33999634\n",
            " 247.05999756 244.83999634 241.97999573 239.52000427 227.00999451\n",
            " 232.30999756 231.94999695 228.33000183 211.02999878 205.36000061\n",
            " 205.08000183 192.72999573 195.49000549 190.63000488 188.69999695\n",
            " 189.86000061 188.22000122 185.16000366 178.97000122 193.6000061\n",
            " 196.58999634 205.94999695 204.5        212.88000488 217.1000061\n",
            " 209.25999451 213.91000366 214.91999817 225.02999878 224.74000549\n",
            " 226.42999268 219.61999512 221.86000061 223.63999939 219.75999451\n",
            " 219.27000427 222.83999634 223.46000671 227.16999817 224.55000305\n",
            " 234.8999939  233.1000061  230.33999634 230.05999756 238.91999817\n",
            " 238.6000061  245.08000183 253.5        252.38000488 254.86000061\n",
            " 253.53999329 258.17999268 255.67999268 260.17001343 264.88000488\n",
            " 228.82000732 228.03999329 235.77000427 242.25999451 241.61000061\n",
            " 233.8500061  234.33999634 228.32000732 230.75       233.41999817\n",
            " 238.30000305 235.00999451 229.00999451 235.         219.61999512\n",
            " 215.63999939 219.94000244 226.83000183 225.86000061 220.83000183\n",
            " 222.1499939  211.3999939  215.         214.08000183 215.58999634\n",
            " 221.71000671 225.61000061 225.00999451 220.67999268 229.58000183\n",
            " 227.44999695 231.78999329 235.53999329 247.1000061  245.86999512\n",
            " 245.19999695 242.80999756 244.78999329 243.49000549 246.6000061\n",
            " 240.61999512 241.22999573 223.21000671 228.69999695 242.55999756\n",
            " 242.13000488]\n",
            "[240.86999512 244.69000244 243.13000488 233.02999878 231.42999268\n",
            " 237.72000122 240.05000305 244.52999878 244.74000549 247.88999939\n",
            " 256.95999146 257.89001465 259.75       261.97000122 256.95001221\n",
            " 253.5        255.58000183 254.67999268 299.67999268 328.13000488\n",
            " 327.70999146 316.22000122 315.01000977 314.92001343 313.30999756\n",
            " 317.47000122 317.22000122 326.57998657 335.54000854 337.14001465\n",
            " 345.08999634 349.92999268 346.10998535 349.3500061  352.17001343\n",
            " 349.98999023 359.51998901 352.22000122 354.82998657 333.04000854\n",
            " 336.33999634 328.92001343 331.29000854 329.94000244 336.20001221\n",
            " 333.02999878]\n",
            "X_train (416, 15, 10)\n",
            "y_train (416,)\n",
            "X_test (46, 15, 10)\n",
            "y_test (46,)\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_5 (LSTM)                (None, 15, 512)           1071104   \n",
            "_________________________________________________________________\n",
            "dropout_42 (Dropout)         (None, 15, 512)           0         \n",
            "_________________________________________________________________\n",
            "lstm_6 (LSTM)                (None, 15, 256)           787456    \n",
            "_________________________________________________________________\n",
            "dropout_43 (Dropout)         (None, 15, 256)           0         \n",
            "_________________________________________________________________\n",
            "lstm_7 (LSTM)                (None, 15, 128)           197120    \n",
            "_________________________________________________________________\n",
            "dropout_44 (Dropout)         (None, 15, 128)           0         \n",
            "_________________________________________________________________\n",
            "lstm_8 (LSTM)                (None, 15, 64)            49408     \n",
            "_________________________________________________________________\n",
            "dropout_45 (Dropout)         (None, 15, 64)            0         \n",
            "_________________________________________________________________\n",
            "lstm_9 (LSTM)                (None, 32)                12416     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 2,117,537\n",
            "Trainable params: 2,117,537\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Compilation Time :  0.012605667114257812\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKp__D3BCxEW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9cf96b15-46b6-4d5f-fbcd-0b28125e4718"
      },
      "source": [
        "model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    batch_size=768,\n",
        "    epochs=300,\n",
        "    validation_split=0.1,\n",
        "    verbose=0)\n",
        "\n",
        "trainScore = model.evaluate(X_train, y_train, verbose=0)\n",
        "print('Train Score: %.2f MSE (%.2f RMSE)' % (trainScore[0], math.sqrt(trainScore[0])))\n",
        "\n",
        "testScore = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test Score: %.2f MSE (%.2f RMSE)' % (testScore[0], math.sqrt(testScore[0])))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Score: 0.04 MSE (0.19 RMSE)\n",
            "Test Score: 0.37 MSE (0.61 RMSE)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrpIOGWzC4uJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        },
        "outputId": "a3c95106-4235-4e2a-b247-c8a0c71d1245"
      },
      "source": [
        "diff = []\n",
        "ratio = []\n",
        "pred = model.predict(X_test)\n",
        "for u in range(len(y_test)):\n",
        "    pr = pred[u][0]\n",
        "    ratio.append((y_test[u] / pr) - 1)\n",
        "    diff.append(abs(y_test[u] - pr))\n",
        "\n",
        "print (pred)\n",
        "print (y_test)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-0.29848665]\n",
            " [-0.39718086]\n",
            " [-0.29616007]\n",
            " [-0.21357691]\n",
            " [-0.2127243 ]\n",
            " [-0.02081632]\n",
            " [-0.48743632]\n",
            " [-0.8065479 ]\n",
            " [-0.6381517 ]\n",
            " [-0.95769817]\n",
            " [-1.0558697 ]\n",
            " [-1.2029407 ]\n",
            " [-1.0354806 ]\n",
            " [-0.959464  ]\n",
            " [-0.8496706 ]\n",
            " [-0.80648977]\n",
            " [-0.88177615]\n",
            " [-0.97056353]\n",
            " [-1.0911952 ]\n",
            " [-0.7049178 ]\n",
            " [ 0.5676964 ]\n",
            " [ 1.258907  ]\n",
            " [ 1.2816898 ]\n",
            " [ 1.3333527 ]\n",
            " [ 1.4369229 ]\n",
            " [ 1.4861785 ]\n",
            " [ 1.5448223 ]\n",
            " [ 1.4095627 ]\n",
            " [ 1.2210661 ]\n",
            " [ 0.9911866 ]\n",
            " [ 0.7729583 ]\n",
            " [ 0.66085166]\n",
            " [ 0.81106395]\n",
            " [ 1.1346172 ]\n",
            " [ 1.1645857 ]\n",
            " [ 1.482544  ]\n",
            " [ 1.3707315 ]\n",
            " [ 1.2867092 ]\n",
            " [ 1.1160017 ]\n",
            " [ 0.68210506]\n",
            " [ 0.29172367]\n",
            " [ 0.29738086]\n",
            " [ 0.56096286]\n",
            " [ 0.98833954]\n",
            " [ 1.0554222 ]\n",
            " [ 1.1880825 ]]\n",
            "[-1.08031194 -0.99565323 -1.03022578 -1.25406136 -1.28952058 -1.15012188\n",
            " -1.09848455 -0.99919922 -0.99454506 -0.92473513 -0.72372664 -0.70311554\n",
            " -0.66189468 -0.61269518 -0.7239478  -0.80040671 -0.75430987 -0.7742558\n",
            "  0.22303085  0.85353791  0.8442296   0.58958929  0.56277355  0.56077906\n",
            "  0.52509801  0.6172917   0.61175122  0.81918652  1.01775786  1.05321708\n",
            "  1.22940398  1.33666762  1.2520089   1.323814    1.38631079  1.33799728\n",
            "  1.5492004   1.38741862  1.44526092  0.96235304  1.03548713  0.87104602\n",
            "  0.92356967  0.89365094  1.03238481  0.96213121]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBNNtkN7C8Sz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "7cecc1e6-2dc8-4fb0-9991-423fe126e8b2"
      },
      "source": [
        "%matplotlib inline \n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt2\n",
        "\n",
        "plt2.plot(pred, color='red', label='Prediction')\n",
        "plt2.plot(y_test, color='blue', label='Ground Truth')\n",
        "plt2.legend(loc='upper left')\n",
        "plt2.show()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}